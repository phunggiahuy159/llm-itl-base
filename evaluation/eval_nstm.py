import sys
sys.path.append("../llm-itl-base")
import argparse
import os
import scipy.io as sio
from utils import sparse2dense
import torch
from metrics import *
import json
from tqdm import tqdm
from topic_models.nstm import encoder


def get_theta(model, dataset, batch_size=1000):
    model.eval()

    N = dataset.shape[0]
    dataset = torch.from_numpy(dataset).cuda()
    nb_batches = int(math.ceil(float(N) / batch_size))

    theta = np.zeros((N, model.K))
    for batch in range(nb_batches):
        start, end = batch_indices(batch, N, batch_size)
        X = dataset[start:end]
        X_theta = model(X)
        theta[start:end] = X_theta.detach().cpu().numpy()

    return theta


def batch_indices(batch_nb, data_length, batch_size):
    # Batch start and end index
    start = int(batch_nb * batch_size)
    end = int((batch_nb + 1) * batch_size)

    # When there are not enough inputs left, we reuse some to complete the batch
    if end > data_length:
        shift = end - data_length
        start -= shift
        end -= shift

    return start, end


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Evaluation')
    parser.add_argument("--model_folder", type=str, required=True)
    parser.add_argument('--dataset', type=str, default='20News')
    parser.add_argument("--inference_bs", type=int, default=500)
    parser.add_argument("--eval_topics", action='store_true')
    parser.add_argument('--TC', type=str, default='cv')
    args = parser.parse_args()

    checkpoint_folder = 'save_models'
    model_epochs = os.listdir(os.path.join(checkpoint_folder, args.model_folder))
    model_epochs = sorted(model_epochs, key=lambda x: int(x.split('-')[1].split('.')[0]))

    # load data
    data_dict = sio.loadmat('datasets/%s.mat' % args.dataset)

    train_data = sparse2dense(data_dict['bow_train'])
    train_label = data_dict['label_train'].reshape(-1)

    test_data = sparse2dense(data_dict['bow_test'])
    test_label = data_dict['label_test'].reshape(-1)

    # save path
    save_path = 'evaluation_output/%s' % (args.model_folder + '.jsonl')
    open(save_path, 'w').close()

    for model_epoch in tqdm(model_epochs):
        # load model
        model = torch.load(os.path.join(checkpoint_folder, args.model_folder, model_epoch), weights_only=False)
        model.eval()

        # infer topic proportion for test
        test_theta = get_theta(model, test_data, batch_size=1000)

        # infer topic proportion for train
        train_theta = get_theta(model, train_data, batch_size=1000)

        ############## evaluate theta ##############
        TP, TN = compute_TP_TN(test_label, test_theta)
        PN = (TP + TN)/2

        # more available metrics
        '''
        # doc cls acc
        acc = rf_cls(train_theta, train_label, test_theta, test_label)

        # metrics used by TopicGPT
        pred = np.argmax(test_theta, axis=1)
        purity, inverse_purity, harmonic_purity = calculate_purity(test_label, pred)

        ari = metrics.adjusted_rand_score(test_label, pred)
        mis = metrics.normalized_mutual_info_score(test_label, pred)
        '''
        ############## evaluate topics ##############
        if args.eval_topics:
            print('Evaluating Topic Coherence (Metrics: %s) ...' % args.TC)
            topic_file = 'save_topics/%s/epoch%s_tm_words.txt' % (args.model_folder, model_epoch.split('.')[0].split('-')[1])
            temp_folder = 'temp_tc/%s/' % args.model_folder
            temp_path = os.path.join(temp_folder, 'epoch%s_tm_words_%s.txt' % (model_epoch.split('.')[0].split('-')[1], args.TC))
            if not os.path.exists(temp_folder):
                os.makedirs(temp_folder)
            open(temp_path, 'w').close()

            if args.TC == 'cv':
                tc_metric = 'C_V'

            # make sure you have unzip 'Wikipedia_bd.zip' before this
            os.system('java -jar palmetto-0.1.5-exec.jar wikipedia_bd %s %s > %s' % (tc_metric, topic_file, temp_path))

            with open(temp_path, 'r') as file:
                content = file.read()
                tc_agg = read_tc(content)

            # eval topics diversity
            with open(topic_file, 'r') as file:
                topics = file.readlines()
                topics = [t.strip().split(' ') for t in topics]

            td = topic_diversity(topics)
        else:
            tc_agg = None
            td = None



        ############## save metrics ############
        opt_dict = {'TP': TP,
                    'TN': TN,
                    'PN': PN,
                    'TC': tc_agg,
                    'TD': td
                    }
        with open(save_path, 'a') as f:
            f.write(json.dumps(opt_dict) + '\n')
